{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table de matières\n",
    "- Lecture du fichier de données\n",
    "- Entrainement du modèle et prédiction\n",
    "- Calcul de la précision (accuracy) du modèle\n",
    "- Résultats de la classification binaire\n",
    "- Sensibilité\n",
    "- Spécificité\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lecture du fichier de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gpa</th>\n",
       "      <th>gre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.177277</td>\n",
       "      <td>594.102992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.412655</td>\n",
       "      <td>631.528607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.728097</td>\n",
       "      <td>553.714399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.093559</td>\n",
       "      <td>551.089985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.141923</td>\n",
       "      <td>537.184894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>1</td>\n",
       "      <td>3.381359</td>\n",
       "      <td>720.718438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>1</td>\n",
       "      <td>3.083956</td>\n",
       "      <td>556.918021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>1</td>\n",
       "      <td>3.114419</td>\n",
       "      <td>734.297679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>1</td>\n",
       "      <td>3.549012</td>\n",
       "      <td>604.697503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>1</td>\n",
       "      <td>3.532753</td>\n",
       "      <td>588.986175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>644 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit       gpa         gre\n",
       "0        0  3.177277  594.102992\n",
       "1        0  3.412655  631.528607\n",
       "2        0  2.728097  553.714399\n",
       "3        0  3.093559  551.089985\n",
       "4        0  3.141923  537.184894\n",
       "..     ...       ...         ...\n",
       "639      1  3.381359  720.718438\n",
       "640      1  3.083956  556.918021\n",
       "641      1  3.114419  734.297679\n",
       "642      1  3.549012  604.697503\n",
       "643      1  3.532753  588.986175\n",
       "\n",
       "[644 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "admissions = pd.read_csv('admissions.csv')\n",
    "admissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Entrainement du modèle et prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrainement du modèle\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "logistic_model = LogisticRegression(solver='liblinear')\n",
    "logistic_model.fit(admissions[['gpa']], admissions['admit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "labels = logistic_model.predict(admissions[['gpa']])\n",
    "admissions['predicted_label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    598\n",
       "1     46\n",
       "Name: predicted_label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions['predicted_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit       gpa         gre  predicted_label\n",
      "0      0  3.177277  594.102992                0\n",
      "1      0  3.412655  631.528607                0\n",
      "2      0  2.728097  553.714399                0\n",
      "3      0  3.093559  551.089985                0\n",
      "4      0  3.141923  537.184894                0\n"
     ]
    }
   ],
   "source": [
    "print(admissions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calcul de la précision (accuracy) du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renommer la colonne admit du DataFrame admissions en actual_label afin d'indiquer plus clairement quelle colonne \n",
    "# contient les libellés prédits (predicted_label) et quelle colonne contient les libellés réels (actual_label).\n",
    "admissions['actual_label'] = admissions['admit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit       gpa         gre  predicted_label  actual_label\n",
      "0      0  3.177277  594.102992                0             0\n",
      "1      0  3.412655  631.528607                0             0\n",
      "2      0  2.728097  553.714399                0             0\n",
      "3      0  3.093559  551.089985                0             0\n",
      "4      0  3.141923  537.184894                0             0\n"
     ]
    }
   ],
   "source": [
    "# Comparer la colonne predicted_label avec la colonne actual_label\n",
    "matches = admissions['predicted_label'] == admissions['actual_label']\n",
    "correct_predictions = admissions[matches]\n",
    "print(correct_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6459627329192547\n"
     ]
    }
   ],
   "source": [
    "# Calculer la précision de la prédiction et affecter la valeur résultante à la variable accuracy \n",
    "predictive_accuracy = len(correct_predictions) / len(admissions)\n",
    "print(predictive_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Résultats de la classification binaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vrai positif ou True positive : le modèle a prédit correctement que l'étudiant serait admis.\n",
    "- Vrai négatif ou True Negative : le modèle a prédit correctement que l'étudiant serait rejeté.\n",
    "- Faux positif ou False Positive : le modèle a prédit à tort que l'étudiant serait admis meme si l'étudiant a été rejeté.\n",
    "- Faux négatif ou False Negative : le modèle a prédit à tort que l'étudiant serait rejeté meme s'il était effectivement admis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "# Extraire toutes les lignes pour lesquelles la valeur de 'predicted_label' et de 'actual_label' sont égales à 1. \n",
    "# Ensuite calculer le nombre de Vrais positifs et assigner le résultat à la variable true_positives\n",
    "true_positive_filter = (admissions['predicted_label'] == 1) & (admissions['actual_label'] == 1)\n",
    "true_positives = len(admissions[true_positive_filter])\n",
    "\n",
    "print(true_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385\n"
     ]
    }
   ],
   "source": [
    "# Extraire toutes les lignes pour lesquelles la valeur de 'predicted_label' et de 'actual_label' sont égales à 0. \n",
    "# Ensuite calculer le nombre de Vrais négatifs et assigner le résultat à la variable true_negatives\n",
    "true_negatives_filter = (admissions['predicted_label'] == 0) & (admissions['actual_label'] == 0)\n",
    "true_negatives = len(admissions[true_negatives_filter])\n",
    "\n",
    "print(true_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sensibilité \n",
    "Sensibilité ou taux de Vrai Positifs (True Positive Rate - TPR) : \n",
    "$$ TPR = \\frac{True ~ Positives}{True ~ Positives + False ~ Negatives}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le nombre de Faux Négatifs (c'est-à-dire ou le modèle a prédit un rejet alors que l'étudiant a été admis)\n",
    "# et assigner le résultat à la variable false_negatives.\n",
    "false_negative_filter = (admissions['predicted_label']) == 0 & (admissions['actual_label'] == 1)\n",
    "false_negatives = len(admissions[false_negative_filter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0492845786963434\n"
     ]
    }
   ],
   "source": [
    "# Calculer la sensibilité et assigner le résultat à la variable sensitivity\n",
    "sensitivity = (true_positives) / (true_positives + false_negatives)\n",
    "print(sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spécificité\n",
    "Spécificité ou taux de Vrais Négatifs (True Negative Rate - TNR) :\n",
    "$$ TNR = \\frac{True ~ Negatives}{False ~ Positives + True ~ Negatives}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le nombre de Faux Positifs (c'est-à-dire ou le modèle a prédit des admissions mais les étudiants ont au final été rejetés)\n",
    "# et assigner le résultat à la variable false_positives \n",
    "false_positive_filter = (admissions['predicted_label']) == 1 & (admissions['actual_label'] == 0)\n",
    "false_positives = len(admissions[false_positive_filter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6280587275693311\n"
     ]
    }
   ],
   "source": [
    "# Calculer la spécificité et assigner le résultat à la variable specificity\n",
    "specificity = (true_negatives) / (false_positives + true_negatives)\n",
    "print(specificity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f7f5615eb1463159f2675cc679f515f07044769360d76f2523e36f14f196a50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
